# -*- coding: utf-8 -*-
"""Cópia de Geoestastica-Atividade Final- Helber Soares.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RQpXc7spykVnBInO0egm5h9r64StSAIt

# Atividade Final Geoestatística

Usando os arquivos baseroubos.cv e Distrito Sao Paulo.zip responda o que se pede abaixo. O arquivo baseroubos.csv contém o ano, o mês e as coordenadas (latitude e longitude) da ocorrência de roubo em São Paulo. As coordenadas foram obtidas por meio de GPS (WGS84). O arquivo Distrito Sao Paulo.zip possui o contorno da cidade de São Paulo com seus distritos.

1) Faça um mapa de pontos dos roubos da cidade de São Paulo no ano de 2016 estático.

2) Faça um mapa de pontos marcado dos roubos da cidade de São Paulo no ano de 2016. Use o mês como marca.

3) Faça um mapa de pontos dos roubos da cidade de São Paulo no ano de 2016
interativo. Quando o mouse passar pelos pontos deseja-se saber o ano e o mês de ocorrência do roubo.

4) Estime a intensidade do processo, usando um kernel gaussiano e o raio estimado pelo método scott.

5) Avalie por meio de um histograma a distância do vizinho mais próximo.

6) Estime a função G de Ripley do processo. Você diria que existe agrupamento dos pontos?

7) Usando o algoritmo DBSCAN encontre os clusters de ponto. Use a seguinte configuração de cluster: 1200 m e 50 pontos.

# Instalando bibliotecas e em seguida pacotes
"""

pip  install libpysal

pip install pointpats

pip install contextily

#Ativando pacotes
import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pyproj
from PIL import Image
import plotly.express as px
import contextily as ctx
import libpysal as ps
from scipy.spatial.distance import pdist
from sklearn.cluster import DBSCAN
from pointpats import (
    distance_statistics,
    QStatistic,
    random,
    PointPattern,
)

"""# 1) Faça um mapa de pontos dos roubos da cidade de São Paulo no ano de 2016 estático."""

#Importando o shapefile de Houston (Houston.zip)
SPshp = gpd.read_file(filename = "Distrito Sao Paulo.zip")

#Apresentando as linhas iniciais do dataframe existente dentro do shapefile
SPshp.head()

#Visualizando informações sobre o objeto
SPshp.info()

#Plotando o shape
SPshp.plot(color = 'white',
           edgecolor = 'black')

#Visualizando o Sistema de Referência de Coordenadas (CRS)
SPshp.crs

#Importando o arquivo baseroubos.csv
dados_crime = pd.read_csv(filepath_or_buffer = "baseroubos.csv",
                          sep = ";",
                          decimal = ",")
#Visualizando as linhas iniciais do objeto
dados_crime.head()

#Visualizando informações sobre o objeto
dados_crime.info()

#Definindo a mudança do Sistema de Referência de Coordenadas desejada
transformacao = pyproj.Transformer.from_crs(crs_from = "EPSG:4326",
                                            crs_to = "EPSG:29193",
                                            always_xy = True)

#Aplicando a transformação nas coordenadas originais
longT, latT = transformacao.transform(dados_crime.LONGITUDE,dados_crime.LATITUDE)

#Incluindo as variáveis logT e latT no objeto dados_sinistro_mod
dados_crime["longT"] = longT
dados_crime["latT"] = latT

#Visualizando as linhas iniciais do objeto
dados_crime.head()

dados_crime.tail()

#Plotando um mapa de pontos

SPshp.plot(color = "white",
           edgecolor = "black")
ax = sns.scatterplot(x = "longT",
                     y = "latT",
                     color = "red",
                     data = dados_crime,
                     s = 4,
                     hue = None)

"""# 2) Faça um mapa de. pontos marcado dos roubos da cidade de São Paulo no ano de 2016. Use o mês como marca."""

#Plotando um mapa de pontos indicando por mes

SPshp.plot(color = "white",
           edgecolor = "black")
ax = sns.scatterplot(x = "longT",
                     y = "latT",
                     data = dados_crime,
                     s = 10,
                     hue = "MES",
                     palette = "Set2")
sns.move_legend(obj = ax,
                loc = "upper left",
                bbox_to_anchor = (1, 1))

"""# 3) Faça um mapa de pontos dos roubos da cidade de São Paulo no ano de 2016
interativo. Quando o mouse passar pelos pontos deseja-se saber o ano e o mês de ocorrência do roubo.
"""

#Plotando um mapa de pontos interativo
mapa_pontos = px.scatter_mapbox(data_frame = dados_crime,
                                lon = "LONGITUDE",
                                lat = "LATITUDE",
                                hover_name = "ANO",
                                hover_data = ["MES"],
                                color_discrete_sequence=["blue"],
                                zoom = 10,
                                height = 1000)
mapa_pontos.update_layout(mapbox_style = "open-street-map")
mapa_pontos.update_layout(margin = {"r":0,"t":0,"l":0,"b":0})
mapa_pontos.show()

"""# 4) Estime a intensidade do processo, usando um kernel gaussiano e o raio estimado pelo método scott."""

#Plotando um mapa de pontos
SPshp.plot(color = "white",
           edgecolor = 'black')
sns.kdeplot(x = "longT",
            y = "latT",
            data = dados_crime,
            fill = True,
            alpha = 0.5,
            cbar = True,
            cmap = "viridis_r",
            bw_method = "scott").set_title("Kernel Gaussiano com raio estimado pelo método scott")

"""# 5) Avalie por meio de um histograma a distância do vizinho mais próximo."""

#Criando um objeto com as coordenadas
pontos = dados_crime[["longT","latT"]]

#Criando o objeto coordenadas (coordendas em um array)
coordenadas = np.asarray(pontos)

#Estimando a função G de Ripley e sua banda de confiança
gest = distance_statistics.g_test(coordinates = coordenadas,
                                  keep_simulations = True)

# distance_statistics.g_test - função que calcula a função G de Ripley
## principais argumentos
# coordinates - coordenadas
# keep_simulations - argumento lógico, para guardar as simulações, permitindo criar o envelope posteriormente

#Calculando a distância do vizinho mais próximo
nn_ixs, nn_dist = PointPattern(points = coordenadas).knn(1)

# PointPattern - define o padrão de pontos no plano
## principais argumentos
# points - coordenadas

#Criando um DataFrame com as distâncias mais próximas
d_dist = pd.DataFrame(data = nn_dist,
                   columns = ["val_dis"])

#Histograma das distâncias mais próximas
fig_hist = sns.histplot(data = d_dist,
                        x = "val_dis")

fig_hist.set(xlabel = "Distância para o vizinho mais próximo",
             ylabel = "Frequência")

plt.show()

# histplot - plota um histograma
## principais argumentos
# data - base de dados (DataFrame)
# x - distância

"""Pode-se observar que existe uma agrupamento de pontos .

# 6) Estime a função G de Ripley do processo. Você diria que existe agrupamento dos pontos?
"""

#Função para plotar a função G de Ripley, sua banda de confiança e o padrão de pontos
f, ax = plt.subplots(
    1, 2, figsize=(9, 3), gridspec_kw=dict(width_ratios=(6, 3))
)
#Plote todas as simulações com linhas finas
ax[0].plot(
    gest.support, gest.simulations.T, color="black", alpha=0.01
)
#E mostre a média das simulações
ax[0].plot(
    gest.support,
    np.median(gest.simulations, axis=0),
    color="cyan",
    label="median simulation",
)


#E a função G do padrão de pontos observado
ax[0].plot(
    gest.support, gest.statistic, label="observed", color="red"
)

#Limpe os rótulos e os eixos
ax[0].set_xlabel("distance")
ax[0].set_ylabel("% of nearest neighbor\ndistances shorter")
ax[0].legend()
ax[0].set_title("Ripley's $G(d)$ function")

#Plote the pattern itself on the next frame
ax[1].scatter(*coordenadas.T)

#E limpe os rótulos e os eixos também
ax[1].set_xticks([])
ax[1].set_yticks([])
ax[1].set_xticklabels([])
ax[1].set_yticklabels([])
ax[1].set_title("Pattern")
f.tight_layout()
plt.show()

"""nao existe um agrupamento de pontos.

# 7) Usando o algoritmo DBSCAN encontre os clusters de ponto. Use a seguinte configuração de cluster: 1200 m e 50 pontos.
"""

#Identificando os cluster com o DBSCAN
clusterer = DBSCAN(eps = 1200,
                   min_samples = 50).fit(coordenadas)

# DBSCAN - algoritmo de identificação de clusters
## principais argumentos
# eps - a distância máxima para que dois pontos sejam considerados vizinhos
# min_samples - o número de pontos em uma vizinhança para que um ponto seja considerado como ponto central

#Cria uma série temporal com eixos rotulados
lbls = pd.Series(data = clusterer.labels_,
                 index = dados_crime.index)

# Series - cria uma série temporal com eixos rotulados
## principais argumentos
# data - valores que comporão a série
# index - rótulos dos valores

#Define especificações da figura (f) e dos eixos (ax)
f, ax = plt.subplots(1, figsize=(12, 12))
#Definindo os pontos que não pertencem a nenhum cluster (ruídos)
noise = dados_crime.loc[lbls == -1, ["LONGITUDE", "LATITUDE"]]
#Plotando os ruídos em cinza
ax.scatter(noise["LONGITUDE"], noise["LATITUDE"], c="grey", s=5, linewidth=0)
#Plote todos os pontos que não são ruídos em vermelho
ax.scatter(
    dados_crime.loc[dados_crime.index.difference(noise.index), "LONGITUDE"],
    dados_crime.loc[dados_crime.index.difference(noise.index), "LATITUDE"],
    c="red",
    linewidth=0,
)
#Adiciona um basemap
ctx.add_basemap(
    ax, crs = "EPSG:4326", source=ctx.providers.CartoDB.PositronNoLabels
)
#Remove os eixos
ax.set_axis_off()
#Mostra a figura
plt.show()